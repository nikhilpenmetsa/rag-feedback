# RAG Feedback System

A sample serverless solution for AI chat applications with integrated user feedback capabilities, built on AWS.

## Overview

This project demonstrates how to implement user feedback integration in AI chat applications. It consists of two main stacks:

1. **Backend Stack**: APIs and services that power the LLM model interactions and handle user feedback for the responses generated by the LLM (capture and retrieval)
2. **Frontend Stack**: Single Page Application (SPA) with a user interface that integrates with the backend APIs

## Architecture

### Backend Components

- **AWS Lambda Functions**:
  - `feedback-lambda`: Processes conversation requests with Claude AI
  - `feedback-writer-lambda`: Stores user feedback in DynamoDB
  - `feedback-reader-lambda`: Retrieves feedback data for analysis
  
- **Amazon Bedrock**: Uses Claude model to generate responses
  
- **Amazon API Gateway**: Provides HTTP endpoints:
  - `/conversation`: For AI conversations
  - `/submit-feedback`: For submitting user feedback
  - `/feedback-data`: For retrieving feedback data
  
- **Amazon DynamoDB**: Stores user feedback with conversation context

### Frontend Components

- **Single Page Application (SPA)**:
  - Clean, modern chat interface
  - Thumbs up/down feedback buttons
  - Text feedback form
  
- **Amazon S3 & CloudFront**: Hosts and delivers the SPA

## Features

- **AI Conversations**: Interact with Claude AI through a simple chat interface
- **User Feedback Collection**: 
  - Capture positive/negative feedback with optional text comments
  - Store feedback with conversation context for analysis
- **Feedback Analysis**: Query and analyze feedback data by conversation or type
- **CORS Support**: Properly configured for cross-origin requests
- **Comprehensive Logging**: Detailed logs for troubleshooting

## Project Structure

```
rag-feedback/
├── cloudformation/       # CloudFormation templates
│   └── template.yaml     # Main backend stack template
├── scripts/              # Deployment and utility scripts
│   ├── deploy.ps1        # Main deployment script
│   └── update-lambda.ps1 # Script to update Lambda code
├── src/                  # Lambda function source code
│   ├── app.py            # Conversation Lambda
│   ├── feedback_writer.py # Feedback submission Lambda
│   ├── feedback_reader.py # Feedback retrieval Lambda
│   └── requirements.txt  # Python dependencies
└── spa/                  # Single Page Application
    ├── cloudformation/   # SPA infrastructure
    │   └── spa-template.yaml # CloudFront/S3 template
    ├── public/           # SPA static files
    │   ├── index.html    # Main HTML file
    │   ├── styles.css    # CSS styling
    │   └── app.js        # JavaScript for chat functionality
    └── scripts/          # SPA deployment scripts
        └── deploy.ps1    # SPA deployment script
```

## Deployment

### Backend Deployment

```powershell
cd scripts
.\deploy.ps1
```

To update Lambda functions without redeploying the entire stack:

```powershell
cd scripts
.\update-lambda.ps1
```

### Frontend Deployment

```powershell
cd spa/scripts
.\deploy.ps1
```

## API Endpoints

### Conversation API

```
POST /conversation
{
  "message": "Your message here"
}
```

### Feedback Submission API

```
POST /submit-feedback
{
  "conversation_id": "uuid",
  "feedback_type": "positive|negative|neutral",
  "feedback_text": "Optional feedback text",
  "original_query": "User's original question",
  "llm_response": "AI's response"
}
```

### Feedback Retrieval API

```
GET /feedback-data
GET /feedback-data?conversation_id=uuid
GET /feedback-data?feedback_type=positive
```

## Local Development

### Backend

```powershell
cd src
pip install -r requirements.txt
```

### Frontend

```powershell
cd spa
npm install
npm start
```

## Data Model

### Feedback Item

```json
{
  "id": "uuid",
  "conversation_id": "uuid",
  "feedback_type": "positive|negative|neutral",
  "feedback_text": "User feedback text",
  "original_query": "User's question",
  "llm_response": "AI's response",
  "timestamp": "ISO datetime"
}
```

## Use Cases

- **Customer Support**: Enhance AI-powered support systems with user satisfaction tracking
- **Content Generation**: Improve AI content creation by analyzing user feedback
- **Knowledge Base Systems**: Refine RAG (Retrieval-Augmented Generation) systems based on user feedback
- **Product Development**: Gather insights on AI feature performance and user satisfaction

## Benefits

- **Continuous Improvement**: Use feedback data to fine-tune AI models and improve responses
- **User Experience**: Create more responsive and user-centered AI applications
- **Performance Metrics**: Track AI system performance through quantifiable feedback data
- **Quality Assurance**: Identify and address problematic AI responses quickly